# Teaching Assistants


* (Coordinator) [Yavar Yeganeh](https://github.com/YavarYeganeh) | [Email](mailto:yavaryeganeh@gmail.com)
  - Office Hours: Sundays and Wednesdays, 12 am to 1 pm, Professor's Office (TBC)  

* [Behnaz Hoseyni](https://github.com/behnazhoseyni) | [Email](mailto:hoseyni.sb@gmail.com)
<!--
* [Erfaan Rostami](https://github.com/Erfaan-Rostami) | [Email](mailto:r.a.erfan@gmail.com)
-->
* [Mostafa Khodayari](https://github.com/MSTF4) | [Email](mailto:mo.khodayari@mail.sbu.ac.ir)

* [Esmail Mafakheri](https://github.com/E008001) | [Email](mailto:e.mafakheri@mail.sbu.ac.ir)   


**Please Note**: 

* A carbon copy (Cc) of your email communications with TAs must be sent to the this [email address](mailto:hhhaji@yahoo.com).
* Response to emails may take a few days. Please be patient!
* You can use [Piazza](https://piazza.com/sbu.ac.ir/fall2020/dl_dsc_f20) for questions and discussions on the related topics.
* Recitation classes and seminars will take place in the [Skype Group](https://join.skype.com/kJ6WepEDrsnt).
* Assignments and the projects should be done utilizing [PyTorch](https://pytorch.org/), except there have been specific instructions for a task.

# Recitation

* **Session One** by [Mostafa Khodayari](https://github.com/MSTF4) was on Wednesday, Shahrivar 26 at 16:00
   - [Toolkit Lab: Getting Started with PyTorch](https://github.com/hhaji/Deep-Learning#Part-2) (Part one) 
   - Notebook: [Colab](https://colab.research.google.com/drive/1qOAGNcdXuLOuJc9Hq9vQP6Cmlq-PJnEN?usp=sharing)
   
 * **Session Two** by [Mostafa Khodayari](https://github.com/MSTF4) was on Tuesday, Mehr 1 at 16:00
   - [Toolkit Lab: Getting Started with PyTorch](https://github.com/hhaji/Deep-Learning#Part-2) (Part two) 
   - Notebook: [Colab](https://colab.research.google.com/drive/1d7gKanEvRhb-6RD6jtkhyIMfAySEz1Yt?usp=sharing)

 * **Session Three** by [Behnaz Hoseyni](https://github.com/behnazhoseyni) was on Wednesday, Mehr 9 at 16:00
   - [Preprocessing Datasets by PyTorch](https://github.com/hhaji/Deep-Learning#Part-3) 
   - Notebook: [Colab](https://colab.research.google.com/drive/1WDbyiac97XQvk246OzHE22J8veD0WsUQ?usp=sharing)
   - Video: Posted in the Skype group (for one month)
   
 * **Session Four** by [Behnaz Hoseyni](https://github.com/behnazhoseyni) was on Tuesday, Mehr 15 at 16:00
   - [Deep Feedforward Networks](https://github.com/hhaji/Deep-Learning#DFN) 
   - Notebook: [Colab](https://colab.research.google.com/drive/15aMn8jQ2RYoad_GSIFdCBxkW4qsVAC72?usp=sharing)
   - Video: Posted in the Skype group (for one month)
   
 * **Session Five** by [Yavar Yeganeh](https://github.com/YavarYeganeh) was on Wednesday, Mehr 23 at 16:00
   - [Using a Neural Network to Fit the Data with PyTorch](https://github.com/hhaji/Deep-Learning#Part-4)
   - Notebook: [Colab](https://colab.research.google.com/drive/1kJsHpvaPYAS522Ay1DAnnejMY-dSNhxZ?usp=sharing)
   - Video: Posted in the Skype group (for one month)
 
 * **Session Six** by [Yavar Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Mehr 29 at 18:00
   - [Regularization for Deep Learning](https://github.com/hhaji/Deep-Learning#RFDL) (Part one)
   - Notebook: [Colab](https://colab.research.google.com/drive/1jzfsfwkAVsnd0-wO_Xtfx28O3oUhWyLk?usp=sharing%22)  
   - Video: Posted in the Skype group (for one month)
   
 * **First Video Tutorial** by [Yavar Yeganeh](https://github.com/YavarYeganeh) was posted on Wednesday, Mehr 30
   - Introduction to Python Classes and Objects
   - Building fully connected neural networks without using machine learning libraries in Python
   - Notebook: [Colab](https://colab.research.google.com/drive/1MswS0QON4atGHxm85oXqCCKR2fypo7Su?usp=sharing) 
   - Video: Posted in the Skype group (for one month)
   
 * **Session Seven** by [Esmail Mafakheri](https://github.com/E008001) was on Wednesday, Aban 7 at 16:00
   - [Convolutional Networks](https://github.com/hhaji/Deep-Learning#CNN)
   - Notebook: [Colab](https://colab.research.google.com/drive/1H7L_ni6fupxMpntLToASEi3FWjjWzfA_?usp=sharing)
   - Video: Posted in the Skype group (for one month)

 * **Session Eight** by [Yavar Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Aban 20 at 18:00 
   - [Regularization for Deep Learning](https://github.com/hhaji/Deep-Learning#RFDL) (Part two)
   - [Optimization for Training Deep Models](https://github.com/hhaji/Deep-Learning#OFTDM)
   - Notebook: [Colab](https://colab.research.google.com/drive/1cass1LqzpmTs1dnasSzgHnvuSnHdODZQ?usp=sharing)
   - Video: Posted in the Skype group (for one month)
  
 * **Session Nine** by [Esmail Mafakheri](https://github.com/E008001) was on Wednesday, Aban 28 at 16:00
   - [Using Convolutions to Generalize](https://github.com/hhaji/Deep-Learning#Part-5)
   - Notebook: [Colab](https://colab.research.google.com/drive/1I6eNUR6whEct9aaI62zmPeda8A2ttEsb?usp=sharing%22)
   - Video: Posted in the Skype group (for one month)  
   
  * **Session Ten** by [Behnaz Hoseyni](https://github.com/behnazhoseyni) was on Tuesday, Azar 4 at 16:00
    - [Optuna: Automatic Hyperparameter Optimization Software](https://github.com/hhaji/Deep-Learning#Part-7) 
    - Notebook: [Colab](https://colab.research.google.com/drive/1Fn3iLMOTMhPz8R3g17wAS-iDVhTk7kGC?usp=sharing)
    - Video: Posted in the Skype group (for one month) 
   
 * **Session Eleven** by [Yavar Yeganeh](https://github.com/YavarYeganeh) will be on Tuesday, Azar 18 at 16:00
   - [Sequence Modeling: Recurrent and Recursive Networks](https://github.com/hhaji/Deep-Learning#SMRARN)
   - Notebook: Will be posted here!  

 * **Session Twelve** by [Yavar Yeganeh](https://github.com/YavarYeganeh) will be on Wednesday, Azar 19 at 16:00
   - [Toolkit Lab 6: Transfer Learning and Other Tricks](https://github.com/hhaji/Deep-Learning#Part-6)
   - Notebook: Will be posted here!
 
 * **Session Thirteen** by [Mostafa Khodayari](https://github.com/MSTF4) will be on Tuesday, Azar 25 at 16:00
   - [Practical Methodology](https://github.com/hhaji/Deep-Learning#Practical-Methodology)
   - Notebook: Will be posted here!  
 
 * **Session Fourteen** by [Behnaz Hoseyni](https://github.com/behnazhoseyni) will be on Tuesday, Dey 2 at 16:00
   - [Applications](https://github.com/hhaji/Deep-Learning#Applications) 
   - Notebook: Will be posted here!  

* **Session Fifteen** by [Esmail Mafakheri](https://github.com/E008001) will be on Tuesday, Dey 9 at 16:00
   - [Autoencoders](https://github.com/hhaji/Deep-Learning#Autoencoders) 
   - Notebook: Will be posted here!  
   
* **Session Sixteen** by [Yavar Yeganeh](https://github.com/YavarYeganeh) will be on Tuesday, Dey 16 at 16:00
   - [Generative Adversarial Networks](https://github.com/hhaji/Deep-Learning#GAN) 
   - Notebook: Will be posted here!  
      
* **Session Seventeen** by [Yavar Yeganeh](https://github.com/YavarYeganeh) will be on Tuesday, Dey 23 at 16:00
   - [Graph Neural Networks](https://github.com/hhaji/Deep-Learning#GNN)
   - Notebook: Will be posted here!  
   

# Assignments 

## Assignment Set 1  

* Install Anaconda and Create an Environment.    
* Install Python Packages (Pandas, Scikit-Learn, Matplotlib) and Jupyter Lab in your new Environment.   
* Install Machine Learning Libraries (PyTorch and TensorFlow).
* Create a GitHub account.   
* Read the [Submission Instruction](https://github.com/hhaji/Deep-Learning/tree/master/Recitation-Assignments#submission-instruction) and Register.
* Use Markdown to Prepare a Readme file for your Repositories. 
* Modify (at least enter your name) and Run the [Sample Notebook](https://github.com/hhaji/Deep-Learning/blob/master/Recitation-Assignments/Assignment_Set_1_Sample.ipynb) in your Environment, then Upload it in your Assignments' Repository.

<-> Deadline: Saturday, Shahrivar 29, 23:59 (Announced at Shahrivar 22)

## Assignment Set 2

* Train neural network models (at least two different networks for each dataset, i.e., no. layers, no. neurons, activation, ...) in either Pytorch or Tensorflow to perform classification on the following datasets:
  
   - [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)   
   - [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) and [Cifar-100](https://www.cs.toronto.edu/~kriz/cifar.html)
   - One different dataset, up to your choice (Optional ~ advantage 10 points: Two different datasets, up to your choice) 
   
* Train neural network models (at least two different networks for each dataset, i.e., no. layers, no. neurons, activations, ...) in either Pytorch or Tensorflow to perform regression on the following datasets:

   - [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing)
   - One different dataset, up to your choice (Optional ~ advantage 10 points: Two different datasets, up to your choice) 
   
* Build and train a simple neural network in either Python or C++ (i.e., not utilizing machine learning libraries). It should be capable of having several layers and neurons as well as other hyperparameters (e.g., activations, loss function). Object-oriented (class/objects) programming should also be employed. Then compare your models with exactly the same settings at Pytorch and Tensorflow (and Keras) for the following data sets:
   
   - Samples from a high-degree perturbed polynomial 
   - [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing)

**Please Note**: Datasets must be downloaded and injected manually (i.e., not loading them by libraries). Moreover, you can find many datasets, for instance, on Kaggle. Besides, Try to develop very good classifiers and regressors based on each model. Careless model architectures and hyperparameter selections, which result in poor performance, will not be appreciated and may be scored very low! 

<-> Deadline: Tuesday, Aban 6, 23:59 (Announced at Shahrivar 22)

## Assignment Set 3

* Create three random tensors, including a 3 * 3 tensor as float, a 4 * 4 tensor as double, and a 5 * 3 * 4 tensor as short type
* Change their elements in the GPU
* Display the order of its elements and its transpose in the memory then use storage offset and contiguous
* Save and load one among the elements of tensors using the torch and the h5py file
* Show the different true and false requires_grad values in Autograd by the backward method

<-> Deadline: Thursday, Mehr 10, 23:59 (Announced at Shahrivar 27)

## Assignment Set 4

* Download the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) by Torchvision and split the data into two parts (training and test with a ratio of 70/30)
* Perform tensor conversion, resizing, and normalization of the dataset, then use Dataloader
* Use the two methods, "nn.Sequential" and "nn.Module", to create a 6-layer fully connected model with hidden layers having Sigmoid, Softmax, and Relu activation functions
* Train (in GPU) and evaluate the models

<-> Deadline: Saturday, Mehr 19, 23:59 (Announced at Mehr 5)

## Assignment Set 5

* Read these [images](https://drive.google.com/drive/folders/1N7vFHFJVmmQadbyPUVW1LsOVgsQUNAdA?usp=sharing) and collate them in one tensor
* Prepare this [data](https://drive.google.com/drive/folders/1N3LD66ysr-msvhoEduVAw5E4emJh20za?usp=sharing) with dataloader for neural networks

<-> Deadline: Tuesday, Mehr 22, 23:59 (Announced at Mehr 8)

## Assignment Set 6

* Apply regularization techniques, including *L<sub>2</sub>* & *L<sub>1</sub>* penalties and data augmentation, to the regression and classification models (the first two parts) that you have developed in [Assignment Set 2](https://github.com/hhaji/Deep-Learning/tree/master/Recitation-Assignments#assignment-set-2), then compare them. 
* Write at least a paragraph regarding (the conclusion of) your experiments and regularization effects. 

**Please Note**: Try to develop very good classifiers and regressors based on each model. Careless model architectures and hyperparameter selections, which result in poor performance, will not be appreciated and may be scored very low! 

<-> Deadline: Wednesday, Aban 21, 23:59 (Announced at Aban 1)

## Assignment Set 7

* Set up a simple convolutional neural network model with convolutional, max-pulling, and linear layers (and suitable activation functions) using a different dataset from those that are used in your previous assignments (its size or classes can also be modified).

<-> Deadline: Thursday, Aban 22, 23:59 (Announced at Aban 8)

## Assignment Set 8

* Apply different optimization algorithms as well as dropout (and/or other regularization methods such as bagging) on the following models:

  - The regression and classification models developed in [Assignment Set 6](https://github.com/hhaji/Deep-Learning/blob/master/Recitation-Assignments/README.md#assignment-set-6) or [2](https://github.com/hhaji/Deep-Learning/blob/master/Recitation-Assignments/README.md#assignment-set-2)
  - At least two different models for a classification or regression dataset (up to your choice, but different from previous ones)

* Write at least a paragraph regarding (the conclusion of, e.g., comparison of) your experiments and modifications.  

**Please Note**: You can find many datasets, for instance, on Kaggle. Moreover, <ins>Try to develop better classifiers and regressors</ins>. Careless model architectures and hyperparameter selections, which result in poor performance, will not be appreciated and may be scored very low! 

<-> Deadline: Friday, Azar 7, 23:59 (Announced at Aban 20)

## Assignment Set 9

* Develop (at least two) convolutional models for an image dataset (up to your choice, but different from previous ones).
* Exercise one of chapter eight, [Deep Learning with PyTorch](https://www.manning.com/books/deep-learning-with-pytorch)

<-> Deadline: Friday, Azar 14, 23:59 (Announced at Aban 30)

## Assignment Set 10

* Run a hyperparameter optimization study (on a model) with the following settings, then find the best hyperparameters (which lead to the best accuracy).

   - 50 Trials | 30, 50, or 70 Epochs | 16, 32, or 64 Batch sizes | At least another hyperparameter, up to your choice
   - Pruning the model if accuracy does not change in 5 epochs

**Please Note**: You may find the following blogs helpful: [Pruning â€” Early Stopping of Poor Trials
](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36) and
[Pruning Unpromising Trials](https://optuna.readthedocs.io/en/latest/tutorial/007_pruning.html#).

<-> Deadline: Tuesday, Azar 18, 23:59 (Announced at Azar 4)

# Final Project

* The final project will be considered as the outcome of the course, which is understanding and effective implementation of deep learning to provide practical solutions to realistic tasks. At least two scenarios for the project can be imagined, applications, and development of deep learning. Developing algorithms and methods is a valuable target, however, it may be challenging. On the other side, applications are recommended for this project. Students should decide on a topic for the project based on their interests as well as discussion with their mentor, who is one of the teaching assistants up to their choice. Mentors could provide advice and assistance during the topic selection and main progress. The following steps and schedule are expected: 

    - Contacting a mentor and deciding on a topic - *Deadline: Mehr 30*
    - Submitting a brief proposal of the project - *Deadline: ~~Aban 30~~ Extended to Azar 7*
    - Proposal approval by the mentor - *Please manage it to be done in Aban!*
    - **The main phase of the project**
    - Submitting a poster or a brief report of the progress - *Deadline: Dey 1*
    - Poster/Progress presentation - *Dey 3 at 16:00*
    - Submitting the final report as well as codes and data - *Deadline: Bahman 10*
    - Seminar presentation -*Bahman 12*
  
**Please Note**: You can find many sample projects as well as datasets on [Kaggle](https://www.kaggle.com/). Moreover, take a look at final projects at Stanford's [CS229](http://cs229.stanford.edu/projects.html). The project will have a notable share in the final score of the course. Creativity, innovations as well as a novelty are (expected and) highly appreciated and will be rewarded accordingly. You should also have an appropriate literature review. Besides, projects will be evaluated by the professor and teaching assistants at the same level. In addition to them, contacts with mentors/assistants are possible through email communications. However, in some cases, skype sessions may be arranged. 

**Poster or Progress Report**: We strongly recommend students to prepare a poster (concerning the progress) of their projects. However, a brief report can also be submitted. Furthermore, students should also present them in a meeting on Wednesday, Dey 3 at 16:00 within the [Skype Group](https://join.skype.com/kJ6WepEDrsnt). This meeting is expected to provide an opportunity for students to be familiar with each other's progress on projects as well as sharing ideas. Consequently, students are asked to manage the meeting themselves and the course staff may not attend (However, the meeting will be recorded!). Those who don't prepare a poster should prepare several slides as well!    

    Poster/Progress Presentation will be on Wednesday, Dey 3 at 16:00! (TBC)

**The Proposal, Poster/Progress, and Final Report's Format and Submission**: The writing and structure of the three documents are important and will be evaluated. The proposal should be at least three paragraphs; The poster should be in a conventional academic form or  a progress report of at least two pages can be submitted; The final report should also be at least four pages. They should be in the academic/publication format. In addition, documents must be in PDF format, which is written either (preferably) with LaTeX in English. You can use available templates; We recommend you to use [NeurIPS Style](https://nips.cc/Conferences/2020/PaperInformation/StyleFiles). You should upload documents (each document in a folder) as well as codes and data into a repository named exactly "Deep_Learning_F20_Project" (you can rename it once the course ended!). Please enter the title of your project as well as the link to its repository in the following link: [Registration](https://docs.google.com/document/d/1wMK93A3ikwGmQKNKvCK1CXL2c3hgMQ2cr-DzDUU5u14/edit?usp=sharing)  

**Seminar Presentations**: Bahman 12 within the [Skype Group](https://join.skype.com/kJ6WepEDrsnt). Please prepare 5 to 10 slides for the presentation. Each student will have 10 minutes to talk and 5 minutes to answer questions. Professor, course staff, and possibly other researchers will attend. Therefore, practice to perfectly present your project. Presentations are also considered in the score of the project. The program of the seminar will be announced prior to the event.
    
    Deep Learning Projects' Seminar will be on Sunday, Bahman 12! (TBC)
    
**Please consult with your mentor for more information!**

<-> The final project was announced at Shahrivar 26! Please follow the schedule!

# Submission Instruction 

* Please register through the link: [Registration](https://docs.google.com/document/d/1wMK93A3ikwGmQKNKvCK1CXL2c3hgMQ2cr-DzDUU5u14/edit?usp=sharing)
* Create a repository inside your Github account with the exact name "Deep_Learning_F20_Assignments".
* After completing all tasks of every assignment set, add related Jupyter notebooks (and/or other files) in a folder in the repository, for instance, assignments-1.ipynb inside Assingment_Set_1 folder, for the first set.
* Projects should be located at another repository named "Deep_Learning_F20_Project".
* Please review the [Projects](https://github.com/hhaji/Deep-Learning/tree/master/Projects) for further instructions.
* Solutions of the exercises, as well as mathematical notations, could be written in [LaTeX](https://github.com/hhaji/Deep-Learning#latex) (which is recommended), either in Jupyter notebook or PDF. MS Office or any other software could also be used, otherwise, images of your handwriting should be included, which is not recommended! Please acknowledge which one is used.

# Scores

* Scores will be announced at the end of the course. 
* Each assignment set is scored from 100 points as well as extra rewards. Therefore, it can be more than 100.
* **Submission after the deadline will not be accepted!** 
* Failure to comply with the [Academic Honor Code](https://github.com/hhaji/Deep-Learning#academic-honor-code) will result in the ZERO score in each set and may have additional consequences!
* The score of the final project will be calculated from 100 points. It may also be more than 100 due to the added rewards! 
* The final score of assignments will be calculated based on the weighted average of them, from 100 points. Moreover, it may be more than 100 due to the added rewards! 
* Scores may be commented. Furthermore, students could also comment on their scores and request for re-evaluation in the form of email, which will be considered at the end of the course.  
